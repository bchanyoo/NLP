{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNRlWTLts1ouuNA+UEvGhHE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bchanyoo/NLP/blob/main/NLP%20Wikidocs_BoW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV8J89SlL8ur",
        "outputId": "239a8246-09eb-4344-b906-dc17c9aac7e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.4.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from konlpy.tag import Okt\n",
        "okt = Okt()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_bag_of_words(document):\n",
        "  #온점 제거 및 형태소 분석\n",
        "  document = document.replace('.', '')\n",
        "  tokenized_document = okt.morphs(document)\n",
        "\n",
        "  word_to_index = {}\n",
        "  bow = []\n",
        "\n",
        "  for word in tokenized_document:\n",
        "    if word not in word_to_index.keys():\n",
        "      word_to_index[word] = len(word_to_index)\n",
        "      #BoW에 기본값 1을 넣기.\n",
        "      bow.insert(len(word_to_index) -1, 1)\n",
        "    else:\n",
        "      #재등장하는 단어의 인덱스\n",
        "      index = word_to_index.get(word)\n",
        "      #재등장한 단어는 해당하는 인덱스의 위치에 1을 더한다.\n",
        "      bow[index] = bow[index] + 1\n",
        "  return word_to_index, bow"
      ],
      "metadata": {
        "id": "YZLOuJ_4MBbS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = '정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.'\n",
        "vocab, bow = build_bag_of_words(doc1)\n",
        "print('vocabulary', vocab)\n",
        "print('bag of words vector', bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmDYn0IbNiEx",
        "outputId": "6428a6ce-daf2-4b6c-bfd4-1f3455273731"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabulary {'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n",
            "bag of words vector [1, 2, 1, 1, 2, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizer 사용\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = ['you know I want your love. because I love you.']\n",
        "vector = CountVectorizer()\n",
        "\n",
        "#코퍼스로부터 각 단어의 빈도수를 기록하기.\n",
        "print('bag of words vector', vector.fit_transform(corpus).toarray())\n",
        "\n",
        "#각 단어의 인덱스 확인\n",
        "print('vocabulary:', vector.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnoEf-OCNt1Q",
        "outputId": "c64eacce-8554-421b-cc82-342f4539bdef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bag of words vector [[1 1 2 1 2 1]]\n",
            "vocabulary: {'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "64LkoLT_SqVn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#불용어 직접 지정\n",
        "\n",
        "text = [\"Family is not an important thing. It's everything.\"]\n",
        "vect = CountVectorizer(stop_words = [\"the\", \"a\", \"an\", \"is\", \"not\"])\n",
        "print('bag of words vector : ', vect.fit_transform(text).toarray())\n",
        "print('vocabulary : ', vect.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0G4ye_9Susj",
        "outputId": "95cef1f5-e844-4e50-dd26-5e330394d14d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bag of words vector :  [[1 1 1 1 1]]\n",
            "vocabulary :  {'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CountVectorizer가 지정한 불용어 사용\n",
        "\n",
        "text = [\"Family is not an important thing. It's everything.\"]\n",
        "vect = CountVectorizer(stop_words = 'english')\n",
        "print('bag of words vector : ', vect.fit_transform(text).toarray())\n",
        "print('vocabulary', vect.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ibbsxh0VTA29",
        "outputId": "3bf91af8-6434-4483-faef-101b2c98606a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bag of words vector :  [[1 1 1]]\n",
            "vocabulary {'family': 0, 'important': 1, 'thing': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NLTK에서 지원하는 불용어 사용.\n",
        "\n",
        "text = [\"Family is not an important thing. It's everything.\"]\n",
        "stop_words = stopwords.words('english')\n",
        "vect = CountVectorizer(stop_words = stop_words)\n",
        "print('bag of words vector : ', vect.fit_transform(text).toarray())\n",
        "print('vocabulary', vect.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JrPeSh4UGPQ",
        "outputId": "26af56a5-3c76-4da9-f27a-2aa21ed25cf7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bag of words vector :  [[1 1 1 1]]\n",
            "vocabulary {'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
          ]
        }
      ]
    }
  ]
}